# Local ASR/LLM Proxy

à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¸²à¸£à¸—à¸³ ASR/LLM Proxy à¸”à¹‰à¸§à¸¢ Go, Rust, à¹à¸¥à¸° Zig

## à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ

à¸ªà¸£à¹‰à¸²à¸‡à¸•à¸±à¸§à¸ˆà¸±à¸”à¸à¸²à¸£à¸„à¸´à¸§ (Queue) à¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸±à¸šà¹„à¸Ÿà¸¥à¹Œà¹€à¸ªà¸µà¸¢à¸‡à¹à¸¥à¸°à¸ªà¹ˆà¸‡à¹„à¸›à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸—à¸µà¹ˆ ASR/LLM service (à¸à¸¶à¸ Worker Pool, Job Queue, à¹à¸¥à¸° Concurrent HTTP Client)

## à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ

```
local-asr-llm-proxy/
â”œâ”€â”€ go/                 # Go + net/http + worker pool
â”œâ”€â”€ rust/               # Rust + axum + tokio
â”œâ”€â”€ zig/                # Zig + Zap (facil.io)
â”œâ”€â”€ test-data/          # Mock backend service
â”œâ”€â”€ benchmark/          # Scripts à¸ªà¸³à¸«à¸£à¸±à¸š benchmark
â””â”€â”€ README.md           # à¸„à¸³à¹à¸™à¸°à¸™à¸³ build/run + à¸•à¸²à¸£à¸²à¸‡ comparison
```

## Dependencies

### Go
- Standard library (`net/http`, `sync`)
- à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£ external dependencies

### Rust
```bash
cargo add axum tokio reqwest serde serde_json uuid num_cpus
```

### Zig
- Zap v0.11.0 (facil.io C library)
- à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£ dependencies à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡

## Build & Run

### Go
```bash
cd go
go mod init local-asr-llm-proxy
go build -o ../bin/asr-proxy-go .
../bin/asr-proxy-go :8080 http://localhost:3000
```

### Rust
```bash
cd rust
cargo build --release
./target/release/local-asr-llm-proxy :8080 http://localhost:3000
```

### Zig
```bash
cd zig
zig build -Doptimize=ReleaseFast
./zig-out/bin/asr-proxy :8080 http://localhost:3000
```

## Docker Build & Run

### Build Images
```bash
# Build all images
docker build -t asr-go   go/
docker build -t asr-rust rust/
docker build -t asr-zig  zig/
```

### Docker Run (HTTP Mode)
```bash
# Create Docker network for proxy + backend
docker network create asr-net

# Start mock backend
docker run -d --network asr-net --name mock-backend -p 3000:3000 \
  golang:1.23-bookworm go run - <<'EOF'
package main
import (
    "encoding/json"
    "math/rand"
    "net/http"
    "time"
)
func main() {
    rand.Seed(time.Now().UnixNano())
    http.HandleFunc("/transcribe", func(w http.ResponseWriter, r *http.Request) {
        time.Sleep(time.Duration(rand.Int63n(40)+10) * time.Millisecond)
        json.NewEncoder(w).Encode(map[string]interface{}{
            "transcription": "mock result",
            "confidence": 0.95,
            "processing_time_ms": rand.Int63n(40)+10,
        })
    })
    http.HandleFunc("/health", func(w http.ResponseWriter, r *http.Request) {
        json.NewEncoder(w).Encode(map[string]string{"status": "ok"})
    })
    http.ListenAndServe(":3000", nil)
}
EOF

# Run Proxy
# Go
docker run -d --network asr-net -p 8080:8080 --name asr-proxy-go asr-go \
  0.0.0.0:8080 http://mock-backend:3000

# Rust
docker run -d --network asr-net -p 8080:8080 --name asr-proxy-rust asr-rust \
  0.0.0.0:8080 http://mock-backend:3000

# Zig
docker run -d --network asr-net -p 8080:8080 --name asr-proxy-zig asr-zig \
  0.0.0.0:8080 http://mock-backend:3000
```

### Test Proxy
```bash
curl -X POST http://localhost:8080/transcribe \
  -H "Content-Type: application/json" \
  -d '{"audio_data":"dGVzdA==","format":"wav","language":"th"}'
```

## Benchmark

```bash
bash benchmark/run.sh
```

à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸ˆà¸°à¸–à¸¹à¸ save à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¸¥à¸‡ `benchmark/results/result_YYYYMMDD_HHMMSS.txt`

*(Methodology: `wrk -t4 -c50 -d3s` à¸œà¹ˆà¸²à¸™ Docker network â€” mock backend à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ container à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™)*

## API Specification

### POST /transcribe

Request:
```json
{
    "audio_data": "base64-encoded-audio",
    "format": "wav",
    "language": "th"
}
```

Response:
```json
{
    "job_id": "uuid",
    "status": "completed",
    "transcription": "mock transcription result",
    "processing_time_ms": 25
}
```

### GET /health

Response:
```json
{
    "status": "ok"
}
```

### GET /stats

Response:
```json
{
    "total_processed": 1000,
    "processing_time_s": 15.5,
    "average_latency_ms": 15.5,
    "throughput": 64.5
}
```

## à¸à¸²à¸£à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š

| Metric | Go | Rust | Zig |
|--------|----|------|-----|
| **Throughput (Avg)** | ~242 req/s | ~1,526 req/s ğŸ† | ~115 req/s |
| **Avg Latency** | ~191ms | ~31ms | ~402ms |
| **Memory Usage** | 2,968 KB | 1,248 KB | 72,499 KB |
| **Binary Size** | 5.7MB | 3.8MB | 7.5MB |
| **Code Lines** | 317 | 207 | 221 |
| **HTTP Server** | net/http | axum 0.8 + hyper | Zap (facil.io) |
| **Concurrency** | goroutines + channels | tokio async | zap threads |
| **HTTP Client** | net/http | reqwest + rustls | std.http.Client |

> **à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸**: à¸œà¸¥à¸‚à¹‰à¸²à¸‡à¸•à¹‰à¸™à¸¡à¸²à¸ˆà¸²à¸ benchmark à¸£à¸¸à¹ˆà¸™à¹à¸£à¸ **à¸à¹ˆà¸­à¸™** Go HTTP client fix (à¹€à¸à¸´à¹ˆà¸¡ `Transport: &http.Transport{MaxIdleConnsPerHost: 100}`) â€” à¸œà¸¥à¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¸«à¸¥à¸±à¸‡ fix: **Go 11,051 req/s à¸Šà¸™à¸°** à¸”à¸¹ [PLAN.md](../PLAN.md) à¸ªà¸³à¸«à¸£à¸±à¸šà¸•à¸±à¸§à¹€à¸¥à¸‚à¸­à¸±à¸›à¹€à¸”à¸•

## Benchmark Results

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      Local ASR/LLM Proxy Benchmark       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Tool     : wrk -t4 -c50 -d3s
  Mode     : Docker network
  Backend  : mock ASR (10-50ms delay per request)

â”€â”€ Go     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Run 1 (warm-up): 253 req/s  latency 181.89ms
  Run 2           : 244 req/s  latency 190.02ms
  Run 3           : 243 req/s  latency 191.05ms
  Run 4           : 245 req/s  latency 189.34ms
  Run 5           : 238 req/s  latency 194.92ms
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Avg: 242 req/s  |  Min: 238  |  Max: 245
  Memory  : 2,968 KB
  Binary  : 5.7MB

â”€â”€ Rust   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Run 1 (warm-up): 1514 req/s  latency 31.51ms
  Run 2           : 1522 req/s  latency 31.30ms
  Run 3           : 1521 req/s  latency 31.35ms
  Run 4           : 1551 req/s  latency 30.71ms
  Run 5           : 1511 req/s  latency 31.00ms
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Avg: 1,526 req/s  |  Min: 1,511  |  Max: 1,551
  Memory  : 1,248 KB
  Binary  : 3.8MB

â”€â”€ Zig    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Run 1 (warm-up): 123 req/s  latency 376.85ms
  Run 2           : 120 req/s  latency 387.55ms
  Run 3           : 110 req/s  latency 425.41ms
  Run 4           : 120 req/s  latency 390.81ms
  Run 5           : 113 req/s  latency 405.90ms
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Avg: 115 req/s  |  Min: 110  |  Max: 120
  Memory  : 72,499 KB
  Binary  : 7.5MB

â”€â”€ Code Lines â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Go  : 317 lines
  Rust: 207 lines
  Zig : 221 lines
```

**Key insight (à¸£à¸¸à¹ˆà¸™à¹à¸£à¸)**: Rust à¸Šà¸™à¸°à¸‚à¸²à¸” ~6.3Ã— à¹€à¸«à¸™à¸·à¸­ Go à¹€à¸à¸£à¸²à¸° `tokio` async I/O multiplexes 50 concurrent connections à¸šà¸™ thread pool à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸šà¸¥à¹‡à¸­à¸ à¸‚à¸“à¸°à¸—à¸µà¹ˆ Go HTTP client default à¹„à¸¡à¹ˆ reuse connections à¸‚à¹‰à¸²à¸¡ goroutines à¹„à¸”à¹‰à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸

**Key insight (à¸«à¸¥à¸±à¸‡ Go fix)**: à¸«à¸¥à¸±à¸‡à¹€à¸à¸´à¹ˆà¸¡ `Transport: &http.Transport{MaxIdleConnsPerHost: 100}` à¹ƒà¸™ Go HTTP client, **Go à¸Šà¸™à¸°à¸”à¹‰à¸§à¸¢ 11,051 req/s** à¹€à¸à¸£à¸²à¸° I/O-wait-dominated workload à¸™à¸µà¹‰ (backend latency 10-50ms) à¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸š goroutine model à¸¡à¸²à¸à¸à¸§à¹ˆà¸² â€” 50 goroutines à¸£à¸­ backend à¸à¸£à¹‰à¸­à¸¡à¸à¸±à¸™à¹„à¸”à¹‰à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¹€à¸ªà¸µà¸¢à¹€à¸§à¸¥à¸² context switch à¹à¸¥à¸° connection pool à¸‚à¸­à¸‡ `net/http` à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰à¹€à¸•à¹‡à¸¡à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸

**à¸šà¸—à¹€à¸£à¸µà¸¢à¸™**: Go HTTP client à¸•à¹‰à¸­à¸‡ config `Transport` à¹ƒà¸«à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡ â€” à¸„à¹ˆà¸² default à¹„à¸¡à¹ˆà¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸š high-concurrency proxy workload **Zig à¸Šà¹‰à¸²à¹€à¸à¸£à¸²à¸°**: `std.http.Client` à¹ƒà¸™ Zig 0.15 à¸ªà¸£à¹‰à¸²à¸‡ client à¹ƒà¸«à¸¡à¹ˆà¸—à¸¸à¸ request + Zap (facil.io) à¹ƒà¸Šà¹‰ memory à¸ªà¸¹à¸‡ (~72MB) à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸ thread stack allocation

### Summary

## à¸ªà¸£à¸¸à¸›à¸œà¸¥

- **Go**: 242 req/s â€” worker pool + buffered channel à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¹à¸•à¹ˆ channel à¹€à¸›à¹‡à¸™ bottleneck à¹€à¸¡à¸·à¹ˆà¸­ backend latency à¸ªà¸¹à¸‡
- **Rust**: 1,526 req/s â€” async tokio à¸ªà¸²à¸¡à¸²à¸£à¸–à¸£à¸±à¸š request à¹ƒà¸«à¸¡à¹ˆà¸‚à¸“à¸°à¸£à¸­ backend à¹„à¸”à¹‰ à¸—à¸³à¹ƒà¸«à¹‰ throughput à¸ªà¸¹à¸‡à¸ªà¸¸à¸”
- **Zig**: 115 req/s â€” `std.http.Client` à¸ªà¸£à¹‰à¸²à¸‡à¹ƒà¸«à¸¡à¹ˆà¸—à¸¸à¸ request à¸¡à¸µ overhead à¸ªà¸¹à¸‡, Zap framework à¹ƒà¸Šà¹‰ memory à¸ªà¸¹à¸‡à¸¡à¸²à¸

## à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸

- **Go**: à¹ƒà¸Šà¹‰ standard library `net/http` â€” worker pool à¸à¸±à¸š buffered channels, 1 goroutine à¸•à¹ˆà¸­ request
- **Rust**: à¹ƒà¸Šà¹‰ `axum 0.8` + `tokio` async, `reqwest` with `rustls-tls` (no libssl dependency)
- **Zig**: à¹ƒà¸Šà¹‰ Zap (facil.io) + `std.http.Client.fetch` forward à¹„à¸› backend à¸ˆà¸£à¸´à¸‡
- **Mock Backend**: simulate ASR processing time 10-50ms per request
- **Benchmark**: `wrk -t4 -c50 -d3s` à¸§à¸±à¸” throughput (req/s) + latency

## à¸—à¸±à¸à¸©à¸°à¸—à¸µà¹ˆà¸à¸¶à¸

| à¸ à¸²à¸©à¸² | à¸—à¸±à¸à¸©à¸° |
|------|------|
| **Go** | Worker pool, channels, `sync/atomic`, `net/http` client |
| **Rust** | `tokio` async, `mpsc` channels, `reqwest`, `Arc<AtomicU64>` |
| **Zig** | Zap framework, thread pool, atomic operations, HTTP client |
